{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report contains, in addition to the code provided by the lecturer, my own code changes and additions, and written answers to answer coursework 10 in Machine Learning and Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries needed\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import time\n",
    "\n",
    "# Seed random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "# Helper functions for linear models\n",
    "def linear ( X, coefficients ):\n",
    "    return np.dot(X, np.transpose(coefficients), )\n",
    "\n",
    "def fit_linear( X, y, features=None ):\n",
    "    \"\"\" \n",
    "        Returns the coefficients of a linear model fit to X,y.\n",
    "        If features is a list of integers, then fit will ignore\n",
    "        any features whose index is not in the list.\n",
    "        ( Returned coefficients for these features will be set\n",
    "        to 0. )\n",
    "    \"\"\"\n",
    "    if features is not None:\n",
    "        # Make a mask\n",
    "        tot_num_features = np.shape(X)[-1]\n",
    "        mask = np.zeros((1,tot_num_features))\n",
    "        mask[0,features] = 1.\n",
    "        # Zero out all irrellevant features\n",
    "        X = X * mask\n",
    "    \n",
    "    # Do linear least squares fit\n",
    "    clf = LinearRegression(fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    return clf.coef_\n",
    "\n",
    "\n",
    "def ridge_regression( X, y, lam=1.0, features=None ):\n",
    "    \"\"\" \n",
    "        Identical to fit_linear, but performs ridge regression\n",
    "        with weight penalty alpha (alternatively known as lambda)\n",
    "    \"\"\"\n",
    "    if features is not None:\n",
    "        # Make a mask\n",
    "        tot_num_features = np.shape(X)[-1]\n",
    "        mask = np.zeros((1,tot_num_features))\n",
    "        mask[0,features] = 1.\n",
    "        # Zero out all irrellevant features\n",
    "        X = X * mask\n",
    "    \n",
    "    # Do ridge regression fit\n",
    "    clf = Ridge(alpha=lam, fit_intercept=False)\n",
    "    clf.fit(X, y)\n",
    "    return clf.coef_\n",
    "\n",
    "def lasso_regression( X, y, lam=1.0, features=None ):\n",
    "    \"\"\" \n",
    "        Identical to fit_linear, but performs lasso regression\n",
    "        with weight penalty alpha (alternatively known as lambda)\n",
    "    \"\"\"\n",
    "    if features is not None:\n",
    "        # Make a mask\n",
    "        tot_num_features = np.shape(X)[-1]\n",
    "        mask = np.zeros((1,tot_num_features))\n",
    "        mask[0,features] = 1.\n",
    "        # Zero out all irrellevant features\n",
    "        X = X * mask\n",
    "    \n",
    "    # Do ridge regression fit\n",
    "    clf = Lasso(alpha=lam, fit_intercept=False, max_iter=1e5)\n",
    "    clf.fit(X, y)\n",
    "    return clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE score\n",
    "# You should modify the function mse_loss to compute\n",
    "# the Mean Square Error given a dataset X, y, and learned\n",
    "# linear model with coefficients learned_coeff.\n",
    "\n",
    "def mse_loss( X, y, learned_coefficients ):\n",
    "    y_pred = linear(X, learned_coefficients)\n",
    "    rss = np.sum(np.square(y_pred - y))\n",
    "    mse = rss / len(X)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (100 datapoints)\n",
      "Linear Regression:    0.057\n",
      "Ridge Regression:     0.057\n",
      "LASSO:                0.058\n",
      "\n",
      "Test Loss (100 datapoints)\n",
      "Linear Regression:    0.169\n",
      "Ridge Regression:     0.167\n",
      "LASSO:                0.158\n"
     ]
    }
   ],
   "source": [
    "# Fitting linear models with num_examples > num_features\n",
    "# Run the following code to see the Mean Square Error of three\n",
    "# linear models fit with Linear Regression, Ridge Regression, and\n",
    "# LASSO when trained on a dataset with 100 examples of 50 features\n",
    "# each. You should add in the appropriate code to calculate the test\n",
    "# error of each trained model on the provided test set X_test,\n",
    "# y_test .\n",
    "\n",
    "# Load generated data\n",
    "X, [y] = np.load(\"./class10_training_a.npy\")\n",
    "X_test, [y_test] = np.load(\"./class10_test.npy\")\n",
    "\n",
    "lin_reg_train_loss = mse_loss(X, y, fit_linear(X, y))\n",
    "ridge_train_loss = mse_loss(X, y, ridge_regression(X, y, lam=1.0))\n",
    "lasso_train_loss = mse_loss(X, y, lasso_regression(X, y, lam=0.003))\n",
    "\n",
    "print(\"Train Loss ({:d} datapoints)\".format(len(X)))\n",
    "print(\"Linear Regression:    {:.3f}\".format(lin_reg_train_loss))\n",
    "print(\"Ridge Regression:     {:.3f}\".format(ridge_train_loss))\n",
    "print(\"LASSO:                {:.3f}\".format(lasso_train_loss))\n",
    "\n",
    "print(\"\\nTest Loss ({:d} datapoints)\".format(len(X)))\n",
    "\n",
    "# Include your code for calculating the loss on the test set (X_test, y_test)\n",
    "# (And remember NEVER to train on the test set)\n",
    "\n",
    "lin_reg_test_loss = mse_loss(X_test, y_test, fit_linear(X, y))\n",
    "ridge_test_loss = mse_loss(X_test, y_test, ridge_regression(X, y, lam=1.0))\n",
    "lasso_test_loss = mse_loss(X_test, y_test, lasso_regression(X, y, lam=0.003))\n",
    "\n",
    "print(\"Linear Regression:    {:.3f}\".format(lin_reg_test_loss))\n",
    "print(\"Ridge Regression:     {:.3f}\".format(ridge_test_loss))\n",
    "print(\"LASSO:                {:.3f}\".format(lasso_test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (25 datapoints)\n",
      "Ridge Regression:     0.047\n",
      "LASSO:                0.146\n",
      "\n",
      "Test Loss (25 datapoints)\n",
      "Ridge Regression:     0.715\n",
      "LASSO:                0.655\n"
     ]
    }
   ],
   "source": [
    "# Fitting linear models with num_features > num_examples\n",
    "# Similar to the above, run the following code to see the train error\n",
    "# of Ridge regression and LASSO, but now trained on a dataset with\n",
    "# only 25 examples. As before, you should add in the appropriate code\n",
    "# to calculate the test error of each trained model on test set (X_test,\n",
    "# y_test) given in the previous code-block.\n",
    "\n",
    "# Load generated data\n",
    "X, [y] = np.load(\"./class10_training_b.npy\")\n",
    "\n",
    "ridge_train_loss = mse_loss(X, y, ridge_regression(X, y, lam=10))\n",
    "lasso_train_loss = mse_loss(X, y, lasso_regression(X, y, lam=0.1))\n",
    "\n",
    "print(\"Train Loss ({:d} datapoints)\".format(len(X)))\n",
    "# Why do we not use Linear Regression?\n",
    "print(\"Ridge Regression:     {:.3f}\".format(ridge_train_loss))\n",
    "print(\"LASSO:                {:.3f}\".format(lasso_train_loss))\n",
    "\n",
    "print(\"\\nTest Loss ({:d} datapoints)\".format(len(X)))\n",
    "# Include your code for calculating the loss on the test set (X_test, y_test)\n",
    "ridge_test_loss = mse_loss(X_test, y_test, ridge_regression(X, y, lam=10))\n",
    "lasso_test_loss = mse_loss(X_test, y_test, lasso_regression(X, y, lam=0.1))\n",
    "\n",
    "print(\"Ridge Regression:     {:.3f}\".format(ridge_test_loss))\n",
    "print(\"LASSO:                {:.3f}\".format(lasso_test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your code on calculating the Mean Squared Error (MSE) to the provided code. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Run the provided code (where the hyper-parameter λ is given) to train 3 different linear models\n",
    "on the data set, class10_training_a, with the OLS, ridge regression and LASSO learning\n",
    "algorithms, respectively. Then, run your modified code to calculate the MSE on the test set,\n",
    "class10_test, with 3 trained linear models, respectively. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Run the provided code (where the hyper-parameter λ is given) to train 2 regularised linear\n",
    "models on the data set, class10_training_b, with ridge regression and LASSO learning\n",
    "algorithms, respectively. Then, run your modified code to calculate the MSE on the test set,\n",
    "class10_test, with 2 trained regularised linear regression models, respectively. Comment\n",
    "on why the OLS cannot be applied to this training data set. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See code above for calculating MSE and results on class10_training_a and class10_training_b. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason OLS cannot be applied to the second training dataset (class10_training_b) is because the number of observations is smaller than the number of features. When this is the case there is no longer a unique solution to the least squares coefficient estimate, instead there are infinitely many solutions. The model we train would fit the trainingset very well, but will not be able to generalize on new observations. I.e. the model would be overfit as it is too flexible for the small amount of data. When we use Ridge or Lasso regression on the other hand we introduce constraints which can allow us to find a unique solution and by reducing flexibility makes overfitting less likely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted LASSO with lambda 0.500, learned parameters:\n",
      "[ 0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0. -0.]\n",
      "Non-zero features : [] (0 total)\n",
      "Train error: 0.949\n",
      "Test error:  1.101\n"
     ]
    }
   ],
   "source": [
    "# Automatic feature selection with LASSO\n",
    "# Similar to the above, run the following code to see the train error\n",
    "# Run this code to fit a linear model to a subset of the Automobile\n",
    "# dataset from the previous class. As before, you should calculate the\n",
    "# test error of the trained model. Also observe the weights learned via\n",
    "# LASSO - how do they compare \n",
    "\n",
    "# Load data\n",
    "X_train, [y_train] = np.load(\"./class10_auto_train.npy\")\n",
    "X_test, [y_test] = np.load(\"./class10_auto_test.npy\")\n",
    "\n",
    "lam = 0.5\n",
    "learned_features = lasso_regression(X_train, y_train, lam=lam)\n",
    "nonzero_features = np.argwhere(~ np.isclose(learned_features, 0.)).squeeze()\n",
    "\n",
    "print(\"Fitted LASSO with lambda {:.3f}, learned parameters:\".format(lam))\n",
    "print(learned_features)\n",
    "print(\"Non-zero features : {} ({:d} total)\".format(list(nonzero_features), \n",
    "                                                   len(nonzero_features)))\n",
    "\n",
    "train_loss = mse_loss(X_train, y_train, learned_features)\n",
    "print(\"Train error: {:.3f}\".format(train_loss))\n",
    "\n",
    "test_loss = mse_loss(X_test, y_test, learned_features)\n",
    "print(\"Test error:  {:.3f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the provided code to train LASSO on the training subset, class10_auto_train,\n",
    "with λ = 0.05, 0.5, respectively. Calculate the MSE on the test subset, class10_auto_test, with\n",
    "those trained LASSO models with 2 different λ values, respectively. Based on your observation,\n",
    "comment on the non-zero features achieved by LASSO when different λ-values are used. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - MSE score with lambda = 0.05: Train error = 0.464. Test error = 0.517. Non-zero features : [0, 1, 3, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - MSE score with lambda 0.50: Train error = 0.949. Test error = 1.101. Non-zero features : []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing with many different lambdas of inceasing value in the code above, including 0.05 and 0.5 we see that as lambda increases, the number of selected non-zero features are reduced. And at lambda = 0.5 we are left with no selected features, as all coefficients are set to zero. This happens because as the penaly term becomes larger with an increasing lamba, the coefficients must become smaller to minimize the error - in the end they all become zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 160 entries.\n",
      "\n",
      "Running cross validation with different values of lambda..\n",
      "Lambda = 0.001\n",
      "Mean loss for fold 1/5: 0.73129\n",
      "Mean loss for fold 2/5: 0.44979\n",
      "Mean loss for fold 3/5: 0.41770\n",
      "Mean loss for fold 4/5: 0.46689\n",
      "Mean loss for fold 5/5: 0.54546\n",
      "Lambda = 0.003\n",
      "Mean loss for fold 1/5: 0.71238\n",
      "Mean loss for fold 2/5: 0.43070\n",
      "Mean loss for fold 3/5: 0.41820\n",
      "Mean loss for fold 4/5: 0.46079\n",
      "Mean loss for fold 5/5: 0.55815\n",
      "Lambda = 0.01\n",
      "Mean loss for fold 1/5: 0.65691\n",
      "Mean loss for fold 2/5: 0.38350\n",
      "Mean loss for fold 3/5: 0.42651\n",
      "Mean loss for fold 4/5: 0.45954\n",
      "Mean loss for fold 5/5: 0.56683\n",
      "Lambda = 0.03\n",
      "Mean loss for fold 1/5: 0.59008\n",
      "Mean loss for fold 2/5: 0.37382\n",
      "Mean loss for fold 3/5: 0.42886\n",
      "Mean loss for fold 4/5: 0.44656\n",
      "Mean loss for fold 5/5: 0.57825\n",
      "Lambda = 0.1\n",
      "Mean loss for fold 1/5: 0.61988\n",
      "Mean loss for fold 2/5: 0.52197\n",
      "Mean loss for fold 3/5: 0.43258\n",
      "Mean loss for fold 4/5: 0.48690\n",
      "Mean loss for fold 5/5: 0.56246\n",
      "Lambda = 0.3\n",
      "Mean loss for fold 1/5: 0.86538\n",
      "Mean loss for fold 2/5: 0.84835\n",
      "Mean loss for fold 3/5: 0.47230\n",
      "Mean loss for fold 4/5: 0.64436\n",
      "Mean loss for fold 5/5: 0.59130\n",
      "Lambda = 1\n",
      "Mean loss for fold 1/5: 1.26581\n",
      "Mean loss for fold 2/5: 1.26581\n",
      "Mean loss for fold 3/5: 0.66907\n",
      "Mean loss for fold 4/5: 0.98855\n",
      "Mean loss for fold 5/5: 0.81076\n",
      "[2.6111299110691064, 2.58021212726361, 2.4932912403845067, 2.417579414834994, 2.6237907435968486, 3.421686398725148, 4.999999999999999]\n",
      "Best lambda: 0.03\n"
     ]
    }
   ],
   "source": [
    "# Similar to the above, run the following code to see the train error\n",
    "# Now implement an appropriate method for choosing the parameter lam\n",
    "# for LASSO on the full automobile dataset. (Code for loading the\n",
    "# dataset is given below).\n",
    "\n",
    "# Load data\n",
    "data = []\n",
    "continuous_features = [ 0, 1, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25 ]\n",
    "\n",
    "# Original data is from https://archive.ics.uci.edu/ml/datasets/automobile\n",
    "with open('./automobile.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter=',', quotechar='\\\"')\n",
    "    for row in csvreader:\n",
    "        try:\n",
    "            # Get all continuous rows\n",
    "            data.append([float(row[i]) for i in continuous_features])\n",
    "        except:\n",
    "            continue # skip this row since data-processing failed\n",
    "\n",
    "data = np.array(data)\n",
    "y = data[:, 0] # target is first value\n",
    "X = data[:, 1:] # training data is the rest\n",
    "\n",
    "# Normalize the data to zero mean and unit std\n",
    "X = (X - np.mean(X, axis=0, keepdims=True)) / np.std(X, axis=0, keepdims=True)\n",
    "y = (y - np.mean(y)) / np.std(y)\n",
    "\n",
    "print(\"Successfully loaded {:d} entries.\\n\".format(len(X)))\n",
    "\n",
    "# Implement your method for selecting an appropriate lambda below:\n",
    "# Selected method is K-fold Cross Validation (tested with K=5 and K=10)\n",
    "\n",
    "# Shuffle data\n",
    "sh = list(range(len(X)))\n",
    "np.random.shuffle(sh)\n",
    "X = X[sh]\n",
    "y = y[sh]\n",
    "\n",
    "# Helper function for getting folds\n",
    "def get_fold(X, y, fold, num_folds):\n",
    "    folds_X = np.array_split(X, num_folds)\n",
    "    test_X = folds_X.pop(fold)\n",
    "    train_X = np.concatenate(folds_X)\n",
    "    \n",
    "    folds_y = np.array_split(y, num_folds)\n",
    "    test_y = folds_y.pop(fold)\n",
    "    train_y = np.concatenate(folds_y)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "print(\"Running cross validation with different values of lambda..\")\n",
    "\n",
    "num_folds = 5  #number of folds we split into\n",
    "lam = [0.001, 0.003, 0.01, 0.03, 0.1,0.3,1] #lambdas we wanto to try\n",
    "sum_loss= []  #list to hold the sum of the mean losses for each lambda\n",
    "\n",
    "for l in lam:\n",
    "    losses = []\n",
    "    print(\"Lambda = \" + str(l))\n",
    "    for i in range(num_folds):\n",
    "        #Get data for fold\n",
    "        train_X, train_y, test_X, test_y = get_fold(X, y, i, num_folds)\n",
    "\n",
    "        #Fit model\n",
    "        learned_coefficients = lasso_regression(train_X, train_y, lam=l)\n",
    "        \n",
    "        #Calculate loss\n",
    "        mean_fold_loss = mse_loss(test_X, test_y, learned_coefficients)\n",
    "        \n",
    "        losses.append(mean_fold_loss)\n",
    "\n",
    "        print(\"Mean loss for fold {:d}/{:d}: {:.5f}\".format(i+1, num_folds, \n",
    "                                                            mean_fold_loss))\n",
    "    \n",
    "    sum_loss.append(sum(losses))\n",
    "\n",
    "best_lambda = lam[np.argmin(sum_loss)]\n",
    "print(sum_loss)\n",
    "\n",
    "print('Best lambda: {}'.format(best_lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted LASSO with lambda 0.030, learned parameters:\n",
      "[ 0.41229806 -0.67706057  0.          0.20655253  0.          0.\n",
      "  0.         -0.          0.          0.03608566  0.06103328 -0.00820271\n",
      " -0.          0.          0.        ]\n",
      "Non-zero features : [0, 1, 3, 9, 10, 11] (6 total)\n",
      "Train error: 0.444\n"
     ]
    }
   ],
   "source": [
    "#After finding the best lambda (0.03) we can do fit with all the training data\n",
    "\n",
    "lam = best_lambda\n",
    "learned_features = lasso_regression(X, y, lam=lam)\n",
    "nonzero_features = np.argwhere(~ np.isclose(learned_features, 0.)).squeeze()\n",
    "\n",
    "print(\"Fitted LASSO with lambda {:.3f}, learned parameters:\".format(lam))\n",
    "print(learned_features)\n",
    "print(\"Non-zero features : {} ({:d} total)\".format(list(nonzero_features), \n",
    "                                                   len(nonzero_features)))\n",
    "\n",
    "train_loss = mse_loss(X, y, learned_features)\n",
    "print(\"Train error: {:.3f}\".format(train_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a proper method learnt in Lectures 8-10 to find out the optimal λ value used\n",
    "in the LASSO learning on the Automobile data set from λ = 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, and\n",
    "1.0. Comment on the non-zero features obtained by the LASSO trained with the optimal λ value\n",
    "by comparing them to those achieved in Class 9. It is essential to justify why the method you use\n",
    "is appropriate to find out the optimal λ value. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See code above for implementation and output. Chose to do a K-fold Cross validation to find the optimal lambda in accordance with (1) and what was adviced in the lecture. The reason for using cross-validation to tune the hyper parameter lambda is that we want to choose a lambda which avoids overfitting by finding the lambda which generalise well across the samples which it learns from in each fold. Thus - the lambda which gave the lowest sum mse across folds was the one chosen. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried both 5-fold and 10-fold cross validation and got the same best lambda = 0.03 in both cases (the output above is K=5 to avoid a very long report). The selected features using lambda = 0.03 when fit on the entire training dataset is [0, 1, 3, 9, 10, 11] which gives an error of 0.444. These are not the same as when we used forward and backward stepwise feature selection in coursework 9, using AICS-score as criterion. This strategy selected the subset feature [0, 1, 3]. These are included in the results given by the LASSO regression, but we also get 3 additional features. We do see that the coefficient of the additional features this week (9, 10, 11) are relatively much closer to zero to the other three. This might indicate that the backward stepwise feature selection we ran last week rightfully chose the features which explains the data best. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Chapter 6.2.3 in An Introduction to Statistical Learning with Applications in R. By Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
